{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda1\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data\n",
    "import sage\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets as dsets\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "# Load train set\n",
    "train = dsets.MNIST('../data', train=True, download=True)\n",
    "imgs = train.data.reshape(-1, 784) / 255.0\n",
    "labels = train.targets\n",
    "\n",
    "# Shuffle and split into train and val\n",
    "inds = torch.randperm(len(train))\n",
    "print(inds.shape)\n",
    "imgs = imgs[inds]\n",
    "labels = labels[inds]\n",
    "val, Y_val = imgs[:6000], labels[:6000]\n",
    "train, Y_train = imgs[6000:], labels[6000:]\n",
    "\n",
    "# Load test set\n",
    "test = dsets.MNIST('../data', train=False, download=True)\n",
    "test, Y_test = test.data.reshape(-1, 784) / 255.0, test.targets\n",
    "\n",
    "# Move test data to numpy\n",
    "test_np = test.cpu().data.numpy()\n",
    "Y_test_np = Y_test.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train, Y_train, val, Y_val):\n",
    "    # Create model\n",
    "    device = torch.device('cuda', 0)\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(train.shape[1], 256),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(256, 10)).to(device)\n",
    "    \n",
    "    # Training parameters\n",
    "    lr = 1e-3\n",
    "    mbsize = 64\n",
    "    max_nepochs = 250\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    lookback = 5\n",
    "    verbose = False\n",
    "\n",
    "    # Move to GPU\n",
    "    train = train.to(device)\n",
    "    val = val.to(device)\n",
    "    # test = test.to(device)\n",
    "    Y_train = Y_train.to(device)\n",
    "    Y_val = Y_val.to(device)\n",
    "    # Y_test = Y_test.to(device)\n",
    "\n",
    "    # Data loader\n",
    "    train_set = TensorDataset(train, Y_train)\n",
    "    train_loader = DataLoader(train_set, batch_size=mbsize, shuffle=True)\n",
    "\n",
    "    # Setup\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    min_criterion = np.inf\n",
    "    min_epoch = 0\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(max_nepochs):\n",
    "        for x, y in train_loader:\n",
    "            # Move to device.\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Take gradient step.\n",
    "            loss = loss_fn(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "        # Check progress.\n",
    "        with torch.no_grad():\n",
    "            # Calculate validation loss.\n",
    "            val_loss = loss_fn(model(val), Y_val).item()\n",
    "            if verbose:\n",
    "                print('{}Epoch = {}{}'.format('-' * 10, epoch + 1, '-' * 10))\n",
    "                print('Val loss = {:.4f}'.format(val_loss))\n",
    "\n",
    "            # Check convergence criterion.\n",
    "            if val_loss < min_criterion:\n",
    "                min_criterion = val_loss\n",
    "                min_epoch = epoch\n",
    "                best_model = deepcopy(model)\n",
    "            elif (epoch - min_epoch) == lookback:\n",
    "                if verbose:\n",
    "                    print('Stopping early')\n",
    "                break\n",
    "\n",
    "    # Keep best model\n",
    "    model = best_model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  2.34099571e-05  2.34370188e-05  9.77293287e-05\n",
      "  1.02607823e-04  9.57539305e-05 -1.93965073e-05  1.62697164e-04\n",
      "  4.39411961e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -2.52791991e-06  4.92162144e-07\n",
      "  1.45987918e-05  1.69605647e-04  3.81801305e-04  7.65882581e-04\n",
      "  1.35505424e-03  1.28962646e-03  1.31344468e-03  1.57128052e-03\n",
      "  6.19581570e-04  7.40961985e-04  2.60475001e-04  2.41801785e-04\n",
      "  1.38686940e-04  1.04807481e-03  1.99641974e-04  2.61493333e-05\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.95922136e-07  3.49721813e-05  1.83059578e-05\n",
      "  7.89880514e-05  1.20867361e-03  1.63314857e-03  2.34416398e-03\n",
      "  3.20577699e-03  4.38866542e-03  4.53540530e-03  2.63962773e-03\n",
      "  2.33351634e-03  2.01404151e-03  1.84401797e-04  1.19216122e-04\n",
      "  8.17402681e-05  4.42473596e-04  1.75308238e-05  1.01963208e-06\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  2.65702450e-06 -3.73868049e-06  1.23747808e-04  2.62671563e-04\n",
      "  1.41763307e-03  2.93368646e-03  5.48410627e-03  4.96418455e-03\n",
      "  4.45074918e-03  4.10804713e-03  3.97085299e-03  2.22058390e-03\n",
      "  4.67264164e-03  3.25541536e-03  4.61588437e-04  1.39473232e-03\n",
      "  6.26349496e-04  1.57730808e-04  3.59065379e-04  5.76831508e-04\n",
      "  1.80003739e-04 -9.62004560e-06 -6.08128806e-05  0.00000000e+00\n",
      "  0.00000000e+00 -9.22494413e-08  8.62249484e-07  4.14778090e-06\n",
      "  3.79113600e-05  2.00180164e-04  2.50939214e-04  8.68587290e-04\n",
      "  7.10456788e-04  9.74905786e-04  5.48295432e-03  5.25326018e-03\n",
      "  2.88047102e-03  5.11613258e-03  5.64182249e-03  7.28828315e-03\n",
      "  7.90498246e-03  3.60627439e-03  4.49649531e-03  4.27069509e-03\n",
      "  3.02034544e-03  1.66012564e-03  2.28513671e-03  1.24272484e-03\n",
      "  6.37391717e-04  1.03994187e-04 -8.87786368e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.95840466e-06\n",
      " -9.78139793e-05  2.49570570e-04  8.85959004e-04  9.33552181e-04\n",
      "  8.00738064e-04  4.49018313e-03  4.62488431e-03  3.33640398e-04\n",
      "  2.71839864e-03  7.35115714e-03  8.04338669e-03  1.00970595e-02\n",
      "  7.12377481e-03  2.96300530e-03  4.47107368e-03  5.46921303e-03\n",
      "  6.17470901e-03  3.99301850e-03  4.75188818e-03  3.36722884e-03\n",
      "  3.01036865e-03  3.92755444e-04  3.11650801e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  3.14521661e-05  3.84371773e-04\n",
      "  3.34968727e-04  3.89565718e-04  2.66851402e-03  2.92118815e-03\n",
      "  6.26131314e-03  4.81226991e-03  4.37922022e-03  3.07308567e-03\n",
      "  4.73550433e-03  7.43159206e-03  1.11764071e-02  1.34223659e-02\n",
      "  1.05924260e-02  8.41078164e-03  9.02263697e-03  7.43640308e-03\n",
      "  4.16089405e-03  4.36334206e-03  4.93497006e-03  3.47459637e-03\n",
      "  1.95242449e-03  3.71135600e-04  1.22275626e-04  0.00000000e+00\n",
      "  0.00000000e+00  2.64795211e-05  2.21525899e-04  3.53527159e-04\n",
      "  1.71982143e-04  1.45832202e-03  1.55475231e-03  2.29493620e-03\n",
      "  5.99990649e-03  5.81266851e-03  5.42912032e-03  5.55118314e-03\n",
      "  5.14531410e-03  6.53176500e-03  1.01362156e-02  7.62721852e-03\n",
      "  7.53849293e-03  1.03180278e-02  1.19787213e-02  5.95224096e-03\n",
      "  5.40528085e-03  5.18818357e-03  3.10225296e-03  2.84660714e-03\n",
      "  3.47979048e-03  4.57027150e-04  1.23077729e-04  0.00000000e+00\n",
      "  2.73556992e-05  1.96371460e-04  5.74023999e-05  1.08133769e-04\n",
      "  3.73295732e-04  2.51674368e-03  2.17456445e-03  1.75435999e-03\n",
      "  4.93076127e-03  7.63749972e-03  8.13064257e-03  6.46003531e-03\n",
      "  4.37836438e-03  8.57914096e-03  1.14220005e-02  9.52215450e-03\n",
      "  8.80633693e-03  1.18899080e-02  1.09516193e-02  8.70881318e-03\n",
      "  8.50599189e-03  3.99531511e-03  2.47428532e-03  2.54389612e-03\n",
      "  2.67471297e-03  8.02968084e-04  1.02456790e-04 -4.46796427e-06\n",
      "  1.74591939e-06  2.03778036e-05  3.45303823e-05 -3.39893789e-04\n",
      "  5.10495149e-04  2.11373010e-03  3.47649587e-03  3.30320678e-03\n",
      "  4.63124325e-03  1.04026358e-02  8.85233322e-03  7.11818024e-03\n",
      "  6.88435842e-03  1.07574528e-02  8.66826786e-03  9.89532067e-03\n",
      "  9.51961888e-03  8.90416518e-03  9.59950920e-03  8.83804172e-03\n",
      "  8.13514549e-03  4.27328071e-03  4.69368147e-03  3.22956180e-03\n",
      "  9.16185826e-04  2.76875225e-04  1.91824312e-04 -4.48314240e-05\n",
      "  1.30372743e-05  2.00556436e-05  1.09331741e-04  9.04661172e-05\n",
      "  4.72977434e-04  1.36068351e-03  3.06009103e-03  6.06708948e-03\n",
      "  8.05945137e-03  1.29526294e-02  1.04201947e-02  6.43526057e-03\n",
      "  5.08069900e-03  8.85714833e-03  1.08175410e-02  8.98672726e-03\n",
      "  3.85889746e-03  6.71818603e-03  3.57232558e-03  5.69487969e-03\n",
      "  6.77955029e-03  4.09990803e-03  5.05618906e-03  3.39850835e-03\n",
      "  1.25713937e-03  2.21872185e-04  1.51846383e-04 -3.88056994e-11\n",
      "  0.00000000e+00  0.00000000e+00  2.54239421e-05  6.70205567e-05\n",
      "  4.89701560e-04  1.65641608e-03  4.95416546e-03  8.25116214e-03\n",
      "  1.07405947e-02  1.31875277e-02  1.12356356e-02  1.19771229e-02\n",
      "  7.24598414e-03  1.20572483e-02  1.81658402e-02  8.42647241e-03\n",
      "  5.58919087e-03  5.80182903e-03  5.08510001e-03  6.34425912e-03\n",
      "  3.85611177e-03  5.28381100e-03  5.61329470e-03  2.06266901e-03\n",
      "  1.58877884e-03  5.27053784e-05  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.91292806e-07\n",
      "  3.38756756e-04  1.79077199e-03  4.12060636e-03  9.97524096e-03\n",
      "  1.17689861e-02  1.34387662e-02  1.15656576e-02  8.72417762e-03\n",
      "  1.06227030e-02  1.74999971e-02  2.02499923e-02  9.27135697e-03\n",
      "  7.53452394e-03  8.28687087e-03  4.40428007e-03  4.49988286e-03\n",
      "  9.39252208e-04  4.27264524e-03  5.78011112e-03  2.96326205e-03\n",
      "  5.47073032e-04  2.96697611e-05  8.36416125e-06  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.24341067e-05\n",
      "  6.06091875e-04  2.66028145e-03  3.63755826e-03  8.97067504e-03\n",
      "  1.09559063e-02  1.35267329e-02  7.86264946e-03  6.68973322e-03\n",
      "  7.90361976e-03  1.17002298e-02  1.23956577e-02  6.96427022e-03\n",
      "  9.34273541e-03  1.27870257e-02  7.95532863e-03  5.10646010e-03\n",
      "  5.69830734e-03  5.31311635e-03  4.42796651e-03  2.72201623e-03\n",
      "  1.56513309e-03  1.58862173e-04 -3.31790277e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.06472619e-06  4.11882787e-04\n",
      "  5.47712414e-04  3.49957950e-03  4.29355101e-03  8.99674713e-03\n",
      "  9.68701777e-03  9.57720469e-03  1.06346707e-02  6.34353048e-03\n",
      "  5.37735465e-03  1.32716108e-02  1.31036175e-02  1.11313251e-02\n",
      "  8.97679015e-03  1.62374953e-02  8.78387336e-03  7.24376521e-03\n",
      "  5.06774606e-03  3.79884899e-03  2.49879207e-03  6.96216022e-04\n",
      "  5.40857060e-04  1.61935110e-04  6.71638342e-07 -5.68103360e-08\n",
      "  0.00000000e+00  1.46351522e-06  2.19387778e-05  3.83566725e-04\n",
      "  3.27143104e-04  2.90712217e-03  4.02356780e-03  6.78601743e-03\n",
      "  1.20404126e-02  6.04472313e-03  7.19453335e-03  7.04713307e-03\n",
      "  7.31546627e-03  9.81103171e-03  1.23323878e-02  1.12143732e-02\n",
      "  1.03754408e-02  1.44000231e-02  8.61873092e-03  7.34608715e-03\n",
      "  4.54029982e-03  3.24666642e-03  2.56666928e-03  7.35622934e-04\n",
      "  5.11145889e-04 -1.69292565e-06  1.90625821e-04 -8.91741365e-07\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.95865357e-05\n",
      "  9.26180151e-04  1.31970162e-03  2.61484899e-03  2.93558674e-03\n",
      "  7.04563144e-03  9.53305552e-03  1.52348145e-02  1.23688179e-02\n",
      "  1.00509665e-02  1.07136068e-02  1.30671496e-02  1.01547949e-02\n",
      "  9.84669463e-03  1.05380963e-02  6.13724204e-03  6.82455736e-03\n",
      "  2.70087700e-03  3.46067359e-03  2.15607953e-03  8.53963253e-04\n",
      " -1.32119011e-04  3.30384443e-04  5.53587597e-07  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.24161209e-05  3.22671289e-04\n",
      "  3.17715812e-04  6.32080161e-04  3.42314648e-03  5.76112586e-03\n",
      "  8.61917986e-03  1.32109104e-02  1.12798320e-02  6.71523827e-03\n",
      "  8.83719711e-03  1.03318928e-02  6.12020749e-03  5.21443793e-03\n",
      "  5.51410189e-03  5.13801567e-03  5.89252266e-03  3.65112787e-03\n",
      "  2.60957882e-04  2.76158148e-03  4.01995499e-03  1.70188854e-03\n",
      "  1.21313953e-03  6.90359830e-04  1.67482018e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.35564575e-05  2.21441525e-04\n",
      "  5.91183415e-04  1.88813718e-03  3.90176993e-03  5.46723900e-03\n",
      "  5.81519778e-03  9.32102273e-03  9.64960839e-03  1.38261649e-02\n",
      "  8.26583193e-03  6.34031006e-03  4.89232593e-03  4.64501312e-03\n",
      "  2.15243696e-03  5.79182687e-03  7.87134273e-03  2.82129862e-03\n",
      "  4.63711659e-03  4.22969366e-03  5.16879549e-03  3.50616691e-03\n",
      "  6.57353729e-04  5.24412844e-05  1.30172982e-04  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -4.26350953e-05  7.75961641e-04\n",
      "  7.31453882e-04  3.58316697e-03  2.93185045e-03  3.64796626e-03\n",
      "  6.24326906e-03  8.92439637e-03  1.09484051e-02  1.10268613e-02\n",
      "  8.56299742e-03  2.77366985e-03  4.66164902e-03  4.03327328e-03\n",
      "  1.77584647e-03  2.24194108e-03  3.46039809e-03  3.88093159e-03\n",
      "  4.32885610e-03  4.35486003e-03  1.72345340e-03  2.42608831e-03\n",
      "  6.86305892e-04 -1.36545073e-04  5.79395321e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  4.48251343e-05  6.53081549e-04\n",
      "  4.02854396e-04  1.59995747e-03  3.33418372e-03  4.37277053e-03\n",
      "  5.20074774e-03  4.38997929e-03  7.21873637e-03  5.56047910e-03\n",
      "  5.35622844e-03  3.77424166e-03  5.41109288e-03  5.84049410e-03\n",
      "  3.81144755e-03  3.38139975e-03  1.51108803e-03  2.50069865e-03\n",
      "  3.04998397e-03  1.90969827e-03  1.91265841e-03  1.83841009e-03\n",
      "  1.91092805e-04  4.35729619e-05  1.69762976e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  6.16599767e-05  2.27829719e-04\n",
      "  2.42345527e-04  1.36206888e-03  2.70379669e-03  1.68396978e-03\n",
      "  3.21249150e-03  5.32278689e-03  3.91968950e-03  6.41530966e-03\n",
      "  6.16540570e-03  4.82586877e-03  4.87046513e-03  6.00197242e-03\n",
      "  3.48124495e-03  2.97210437e-03  1.91167793e-03  1.11298965e-03\n",
      "  9.25092565e-04  7.11849368e-04  4.02746043e-04  3.25775869e-04\n",
      "  9.10960481e-05 -6.07791556e-06 -8.01146962e-06  0.00000000e+00\n",
      "  0.00000000e+00  3.64185932e-08  2.57603831e-06  2.13417225e-04\n",
      "  1.19564124e-04  4.34938935e-04  9.15206991e-04  2.03462805e-03\n",
      "  2.68242348e-03  4.04275409e-03  4.00671714e-03  6.53540880e-03\n",
      "  2.99090488e-03  5.32086803e-03  4.78706502e-03  3.56289371e-03\n",
      "  5.16559295e-03  3.91002629e-03  2.61349573e-03  9.47156890e-04\n",
      "  6.07105300e-04  5.74822710e-04  4.22448534e-04 -8.66325498e-07\n",
      " -1.24038777e-04 -1.31427000e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.07372092e-05\n",
      "  1.96223161e-05  2.18385148e-04  3.82224411e-04  7.09214990e-04\n",
      "  3.34873757e-04  7.98006083e-04  1.94580477e-03  2.74975501e-03\n",
      "  4.91917355e-03  5.00819640e-03  2.17613588e-03  2.19152730e-03\n",
      "  2.43314200e-03  2.36202980e-04  6.08192039e-04  1.01233167e-03\n",
      "  1.12931404e-03  4.99923857e-04  3.76758094e-04  8.67249233e-05\n",
      "  1.37882307e-06  2.75395966e-06  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  5.17000638e-05 -5.70432530e-06  7.17215332e-05  3.92317542e-04\n",
      "  1.43521511e-03  2.15697995e-03  1.74750091e-03  3.14368997e-03\n",
      "  3.51892835e-03  5.99575846e-04  4.34631540e-03  3.40947698e-03\n",
      "  4.14949774e-03  1.99875814e-03  1.30930932e-03  7.77870152e-04\n",
      "  6.48314299e-04  1.85920535e-04  1.84990754e-04  1.90859186e-05\n",
      " -2.01002695e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -8.55606049e-06 -9.80761833e-05 -1.67087405e-04  1.98605301e-04\n",
      "  5.59444300e-04  6.73974332e-04  6.26210183e-04 -6.49707734e-04\n",
      "  1.72691159e-04  9.19224531e-04  2.36043506e-03  1.64699577e-03\n",
      "  1.89109830e-03  2.01209923e-03  1.05904838e-03  1.14081183e-03\n",
      "  4.67252550e-04  1.10316828e-04  1.21986882e-04  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  5.87998272e-08  4.03775678e-05  3.45497392e-06  1.78756891e-05\n",
      "  1.17243423e-05  1.30069559e-04  2.10803967e-04  1.58597353e-04\n",
      "  8.61996905e-05  4.39379493e-04  1.97412485e-04  4.34220613e-05\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.303490883274465\n",
      "0.0029381261266255934\n",
      "0.0037325874650201746\n"
     ]
    }
   ],
   "source": [
    "sage_values = sage.load('./results/mnist_sage.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "psave_values=np.loadtxt(\"C:\\\\Users\\\\hp\\\\Desktop\\\\mnist\\\\metric\\\\psave_gau.txt\")\n",
    "psave_values=psave_values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "psave_values_gau =np.loadtxt(\"C:\\\\Users\\\\hp\\\\Desktop\\\\mnist\\\\metric\\\\psave_gau.txt\")\n",
    "psave_values_p =np.loadtxt(\"C:\\\\Users\\\\hp\\\\Desktop\\\\mnist\\\\metric\\\\psave_pos.txt\")\n",
    "psave_values_b =np.loadtxt(\"C:\\\\Users\\\\hp\\\\Desktop\\\\mnist\\\\metric\\\\psave_bio.txt\")\n",
    "psave_values_e =np.loadtxt(\"C:\\\\Users\\\\hp\\\\Desktop\\\\mnist\\\\metric\\\\psave_exp.txt\")\n",
    "psave_values_n =np.loadtxt(\"C:\\\\Users\\\\hp\\\\Desktop\\\\noweight.txt\")\n",
    "gau=np.loadtxt(\"C:\\\\Users\\\\hp\\\\Desktop\\\\gau.txt\")\n",
    "psave_values_gau=psave_values_gau.flatten()\n",
    "psave_values_p=psave_values_p.flatten()\n",
    "psave_values_b=psave_values_b.flatten()\n",
    "psave_values_n=psave_values_n.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.86264515e-09 -1.67638063e-08 -1.67638063e-08\n",
      " -2.42143869e-08 -3.53902578e-08 -3.91155481e-08  2.60770321e-08\n",
      " -1.62050128e-07 -1.84401870e-07 -2.19792128e-07 -5.79282641e-07\n",
      " -4.47034836e-08 -4.09781933e-08 -1.34110451e-07 -1.06170774e-07\n",
      " -5.02914190e-08  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -2.23517418e-08 -1.43423676e-07 -2.45869160e-07\n",
      " -2.98023224e-07  6.07222319e-07  1.09896064e-06 -1.80117786e-06\n",
      " -2.57417560e-06 -9.49949026e-07 -6.14672899e-08 -6.50994480e-06\n",
      " -2.48849392e-06 -3.60608101e-06 -2.91503966e-06 -3.26894224e-06\n",
      " -1.73598528e-06 -6.10947609e-07 -4.06056643e-07 -1.84401870e-07\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.11758709e-08 -2.57045031e-07 -6.03497028e-07\n",
      " -2.92435288e-07  1.65216625e-06  9.17539001e-06  1.12727284e-05\n",
      "  1.22375786e-06  1.24238431e-05  4.62271273e-05  1.99526548e-05\n",
      "  2.41044909e-05  2.16066837e-07 -1.26548111e-05 -8.44150782e-06\n",
      " -5.16325235e-06 -3.73274088e-06 -2.18302011e-06 -9.89064574e-07\n",
      " -5.77419996e-08  1.86264515e-09 -2.79396772e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.86264515e-08\n",
      "  2.42143869e-08  1.69500709e-07  1.64844096e-06  4.59142029e-06\n",
      "  1.63689256e-05  3.02735716e-05  3.30172479e-05  4.02573496e-05\n",
      "  1.00737438e-04  1.06381252e-04  5.75352460e-05 -3.92645597e-06\n",
      " -1.50501728e-06 -1.47949904e-05 -2.64309347e-06  4.41633165e-06\n",
      " -1.60206109e-05  4.22704965e-04 -6.21229410e-05  2.52008066e-03\n",
      "  2.52087414e-03 -5.49480319e-07 -2.06753612e-07  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  6.14672899e-08\n",
      "  6.29574060e-07  5.06639481e-07  8.48248601e-06  1.37742609e-05\n",
      "  3.79662961e-05  4.81121242e-05  6.50286674e-05  1.32247806e-05\n",
      "  3.62750143e-05  4.26732004e-06  4.04752791e-05  1.48862600e-05\n",
      " -7.89705664e-05 -2.22005695e-03 -1.06999651e-04 -9.89716500e-05\n",
      " -2.44252943e-03  7.49342144e-06 -6.01615757e-05  2.52036750e-03\n",
      "  2.52044573e-03 -5.73694706e-07 -7.37607479e-07  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.63215804e-07\n",
      "  1.12876296e-06  3.62843275e-06  1.20345503e-05  1.36457384e-05\n",
      "  2.13216990e-05  5.76823950e-05  2.80551612e-05 -5.53205609e-07\n",
      "  3.24472785e-06 -3.71709466e-05 -8.07549804e-05 -3.46451998e-06\n",
      "  1.68574974e-04  2.45012343e-05 -2.66544521e-06 -2.65333802e-05\n",
      "  9.29981470e-05 -1.79242343e-05 -4.80338931e-05  5.92358410e-05\n",
      "  3.27397138e-05 -4.46662307e-06 -1.70804560e-06 -3.72529030e-09\n",
      "  0.00000000e+00  2.98023224e-08  2.98023224e-08  1.53481960e-06\n",
      "  5.09247184e-06  1.20121986e-05  3.60943377e-05  1.48359686e-05\n",
      "  5.74067235e-06  5.08613884e-05 -3.45706940e-06  8.95559788e-06\n",
      " -1.12000853e-05 -1.73859298e-05 -3.92850488e-05  2.51231529e-03\n",
      "  1.53439119e-04  7.89426267e-05  2.65764073e-04  2.77603045e-04\n",
      "  4.80804592e-05  6.50957227e-05  2.96495855e-05  6.70552254e-07\n",
      " -2.05822289e-06 -5.53205609e-07 -1.38767064e-06 -1.30385160e-08\n",
      "  0.00000000e+00  3.16649675e-08  4.41446900e-07  1.00396574e-06\n",
      "  5.72204590e-06  1.42101198e-05  1.94851309e-05  3.64836305e-05\n",
      "  4.81046736e-05  9.86903906e-05  1.82503834e-04 -5.36926091e-05\n",
      " -4.29600477e-05 -2.22604722e-05  2.51452066e-03  6.22775406e-05\n",
      "  2.21934170e-05 -1.96509063e-06  4.97860834e-04  2.52884626e-03\n",
      "  1.46223232e-04  4.11327928e-05  4.59589064e-05 -4.94904816e-06\n",
      " -1.88611448e-05 -3.55951488e-06 -5.06639481e-07 -5.40167093e-08\n",
      "  3.72529030e-09  7.82310963e-08  1.35973096e-07  8.88481736e-07\n",
      "  3.44775617e-06  1.31838024e-05  1.26361847e-05  1.80117786e-05\n",
      "  2.23312527e-05  8.75778496e-05  5.10588288e-05 -2.44642049e-03\n",
      " -1.72890723e-05  3.50847840e-05  2.49910355e-03  2.49548443e-03\n",
      "  1.75291672e-04  3.22647393e-05 -6.41811639e-05  4.65530902e-05\n",
      "  2.51584314e-03  1.45545229e-04  3.80463898e-05 -2.58612633e-03\n",
      " -1.48881227e-05 -5.23217022e-06 -5.88595867e-07 -3.91155481e-08\n",
      " -3.72529030e-09  0.00000000e+00  1.49011612e-07  4.24683094e-07\n",
      "  1.13621354e-07  1.20010227e-05  4.09595668e-06  3.07578593e-05\n",
      " -1.12242997e-05 -3.27955931e-05 -9.05804336e-05 -2.20537186e-05\n",
      "  8.85389745e-05 -2.59395689e-03 -1.72985718e-04 -1.43775716e-04\n",
      "  2.41966918e-04 -1.02948397e-05 -7.53980130e-05 -1.04311854e-04\n",
      "  5.66970557e-05  1.56955793e-04 -2.52497010e-03 -2.66860798e-03\n",
      " -1.35768205e-05 -2.75857747e-06 -7.22706318e-07 -3.35276127e-08\n",
      "  0.00000000e+00  1.37835741e-07 -2.27242708e-07  9.12696123e-08\n",
      " -4.03448939e-06 -1.49570405e-06 -6.48200512e-07  4.91105020e-05\n",
      "  9.76398587e-05  5.93271106e-05  2.21822411e-05 -2.28653103e-03\n",
      " -2.34471075e-03 -7.73780048e-05 -1.00469217e-04 -1.13781542e-04\n",
      " -8.91070813e-05  2.64402479e-05  3.98363918e-05 -1.40026212e-04\n",
      " -3.24342400e-05  1.44081190e-04 -2.48460844e-03 -2.61822343e-03\n",
      " -8.16397369e-06 -1.02818012e-06 -3.57627869e-07 -2.79396772e-08\n",
      "  0.00000000e+00  1.11758709e-08 -1.08033419e-07 -3.74391675e-07\n",
      " -3.60421836e-06  2.12714076e-06  2.39275396e-05  4.24981117e-05\n",
      "  3.01990658e-05  5.09675592e-05 -9.74070281e-05 -3.06107104e-05\n",
      " -2.51076184e-03 -2.35521048e-03 -2.59039178e-03 -2.58714706e-03\n",
      " -6.68335706e-05 -3.70666385e-05  5.47431409e-05 -1.08599663e-04\n",
      " -5.88521361e-05  1.58218667e-04  8.84849578e-05  6.86943531e-06\n",
      "  6.75208867e-06 -5.40167093e-07 -1.21071935e-07  0.00000000e+00\n",
      "  0.00000000e+00  3.72529030e-09  7.45058060e-08 -2.40281224e-07\n",
      " -6.05359674e-07  1.30534172e-05  7.03837723e-05  9.70754772e-05\n",
      "  2.52435356e-03 -8.84328038e-05 -6.39334321e-05 -2.49242410e-03\n",
      " -2.49574520e-03 -1.08793378e-04 -1.66313723e-04 -2.50239298e-03\n",
      " -5.42923808e-05  2.05617398e-05 -1.36550516e-05 -6.36093318e-05\n",
      " -2.39163637e-05  1.37507915e-04  6.23017550e-05  2.62483954e-05\n",
      "  8.50856304e-06  6.87316060e-07 -1.11758709e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.86264515e-09 -3.11061740e-07\n",
      "  3.70666385e-07  1.99787319e-05  4.93191183e-05  2.51053646e-03\n",
      "  2.50337273e-03 -6.39352947e-05 -2.35661864e-05 -2.34190747e-03\n",
      "  4.96357679e-05 -6.73979521e-05 -1.32247806e-04 -7.20266253e-05\n",
      " -6.21993095e-05  1.21582299e-04 -4.72180545e-06 -6.94729388e-05\n",
      "  2.86623836e-05  1.50352716e-05  3.83257866e-05  1.03898346e-05\n",
      "  5.18187881e-06  1.42119825e-06  6.89178705e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.58793545e-09  3.16649675e-07\n",
      " -1.07102096e-06 -2.67647393e-03 -2.58904882e-03 -1.13818794e-04\n",
      " -2.19680369e-05  4.59644943e-05  3.48201022e-04  1.69286504e-04\n",
      "  4.73987311e-05 -3.86685133e-05 -2.66120210e-03 -2.56574154e-03\n",
      "  1.11404806e-04  2.53971666e-05  4.36473638e-05 -9.71555710e-05\n",
      " -6.06290996e-06  1.58138573e-06  8.68719071e-05  1.44280493e-05\n",
      "  5.96046448e-08  9.31322575e-09  1.49011612e-07  7.45058060e-09\n",
      "  0.00000000e+00  9.31322575e-09  3.09199095e-07  4.15369868e-07\n",
      " -2.64123082e-06  1.13176182e-04 -5.56241721e-05 -1.28637999e-04\n",
      " -1.39737502e-04 -1.73777342e-04 -1.00858510e-04  9.69562680e-05\n",
      " -2.43738480e-03 -2.64291652e-03 -2.52734683e-03  2.76530161e-04\n",
      "  2.50176527e-03 -1.15968287e-04 -9.15061682e-05 -9.09361988e-05\n",
      " -1.33030117e-05  6.72657043e-05  4.14960086e-05  1.47875398e-05\n",
      " -3.52226198e-06 -1.52736902e-07  1.34110451e-07  2.60770321e-08\n",
      "  0.00000000e+00  0.00000000e+00  5.21540642e-07 -2.23517418e-08\n",
      "  4.98071313e-06  2.51746178e-03  2.15960667e-04  7.78604299e-05\n",
      " -7.82869756e-05 -9.49949026e-05 -9.06903297e-05  3.70368361e-05\n",
      "  7.40438700e-05 -6.41494989e-05 -5.31524420e-05 -1.79577619e-05\n",
      " -5.22993505e-05 -2.44324654e-03 -2.32015364e-03 -1.05276704e-05\n",
      " -4.12948430e-05  1.17791817e-04  5.49871475e-05  1.14962459e-05\n",
      " -1.16415322e-06  8.27014446e-07  4.84287739e-08  4.09781933e-08\n",
      "  0.00000000e+00  1.49011612e-08  4.78699803e-07 -6.70552254e-08\n",
      " -8.82893801e-07  2.52322853e-03  2.51905620e-03  1.10529363e-05\n",
      " -1.55959278e-05 -1.84215605e-05  2.49194726e-03  2.52643041e-03\n",
      "  2.69916095e-03  2.12900341e-06 -2.41495669e-03 -2.57608294e-03\n",
      " -2.70582922e-03 -2.56673619e-03 -1.03350729e-04 -5.25824726e-06\n",
      " -2.11484730e-05  1.72860920e-04  7.79144466e-05  1.64322555e-05\n",
      "  3.68058681e-06 -4.63798642e-07  7.26431608e-08  1.30385160e-08\n",
      "  0.00000000e+00  7.45058060e-09 -2.08616257e-07  1.15483999e-06\n",
      "  9.94279981e-06 -4.04547900e-05 -4.48524952e-06 -4.23248857e-05\n",
      " -2.22455710e-05  2.87368894e-05 -3.66605818e-05  1.29248947e-05\n",
      " -3.65730375e-05 -2.45032273e-03 -2.50338390e-03 -2.49608979e-03\n",
      " -6.00721687e-05 -6.24358654e-06 -1.65216625e-05  1.30739063e-05\n",
      "  2.74386257e-05  1.18456781e-04  5.75371087e-05  2.77534127e-06\n",
      " -3.92831862e-06 -1.56648457e-06  2.66358256e-07  0.00000000e+00\n",
      "  0.00000000e+00  3.72529030e-09  1.06170774e-07  3.10689211e-06\n",
      "  6.21005893e-06 -1.33924186e-05  3.15140933e-05 -1.11266971e-04\n",
      "  8.44895840e-06  1.08461827e-05  2.32681632e-05  2.56653875e-05\n",
      " -2.16904469e-03  2.09191814e-04  1.58343464e-05  7.18683004e-05\n",
      "  4.70131636e-06 -6.01224601e-05 -1.06170774e-05  2.55685300e-05\n",
      "  3.38517129e-05  4.73223627e-05  1.87568367e-06 -3.49245965e-06\n",
      " -6.55278563e-06 -2.16066837e-06  1.30385160e-07  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  7.05942512e-07  5.96046448e-06\n",
      "  4.86150384e-06  8.56444240e-06 -1.48452818e-05 -6.93239272e-05\n",
      " -9.51830298e-05 -5.97313046e-05 -6.15231693e-06  3.18214297e-05\n",
      "  1.17441639e-04  8.33198428e-05  1.17629766e-04 -6.27897680e-05\n",
      " -6.55613840e-05 -6.16926700e-05 -3.63383442e-05 -1.38580799e-06\n",
      "  7.87898898e-06 -8.67620111e-06  1.48452818e-05  3.15718353e-06\n",
      " -2.43820250e-06 -4.89875674e-07  9.31322575e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  3.16649675e-07  1.93715096e-06\n",
      "  6.27711415e-07  1.72797590e-05  4.69386578e-05 -2.58889049e-05\n",
      " -9.57120210e-05 -1.14344060e-04 -9.16607678e-05 -4.26787883e-05\n",
      " -2.12391652e-03 -3.56789678e-05 -6.17820770e-05 -5.77922910e-05\n",
      " -4.41204756e-05 -5.61624765e-05 -4.54559922e-05 -6.12065196e-06\n",
      " -1.45882368e-05  1.03041530e-05  7.04824924e-06 -9.44361091e-07\n",
      " -1.08033419e-06 -2.77534127e-07 -2.42143869e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  6.51925802e-08  5.96046448e-08\n",
      " -5.83007932e-07 -2.05822289e-06  1.61677599e-05  6.01671636e-05\n",
      "  6.23445958e-05  3.38014215e-05  5.87049872e-05  1.49872154e-04\n",
      " -2.23703682e-05 -2.65892595e-05 -2.84463167e-05 -3.11750919e-05\n",
      " -5.13363630e-05 -4.06689942e-05 -2.39536166e-05 -1.05686486e-05\n",
      " -4.41260636e-06  4.48524952e-06  1.05984509e-06 -9.77888703e-07\n",
      " -3.42726707e-07 -1.26659870e-07  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  9.31322575e-09\n",
      "  7.11530447e-07  7.46920705e-07  3.26894224e-06  1.26492232e-05\n",
      "  1.47484243e-05  5.09712845e-05  4.76595014e-05  4.96506691e-05\n",
      " -3.66568565e-06 -2.36965716e-05  5.96046448e-08 -6.16908073e-06\n",
      " -2.00234354e-06 -9.40635800e-07 -6.64964318e-07 -4.97512519e-06\n",
      " -4.12575901e-06  1.89989805e-07 -2.98023224e-07 -2.17929482e-07\n",
      " -2.98023224e-08  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  2.57045031e-07  3.57627869e-07  1.13248825e-06  3.15159559e-06\n",
      "  9.25920904e-06  1.10790133e-05  1.62646174e-05  1.64266676e-05\n",
      " -1.47521496e-05 -1.20922923e-05 -6.42426312e-06 -3.95998359e-06\n",
      " -1.66893005e-06 -1.25728548e-05 -4.09781933e-06 -5.38676977e-06\n",
      " -3.59863043e-06 -1.42864883e-06 -7.37607479e-07 -2.42143869e-07\n",
      " -5.40167093e-08  5.58793545e-09  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -5.58793545e-09 -1.54599547e-07 -1.47148967e-07  4.33996320e-07\n",
      "  1.04308128e-06 -1.70804560e-06 -4.10899520e-06 -1.16582960e-05\n",
      " -1.17979944e-05 -1.11926347e-05 -9.46782529e-06 -8.90716910e-06\n",
      " -4.62681055e-06 -6.26221299e-06 -2.57976353e-06 -1.67265534e-06\n",
      " -1.03563070e-06 -3.25962901e-07 -7.45058060e-08 -2.60770321e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.86264515e-09 -1.30385160e-08\n",
      " -1.86264515e-08 -6.51925802e-08 -1.34110451e-07 -2.44006515e-07\n",
      " -3.03611159e-07 -5.34579158e-07 -8.64267349e-07 -1.04494393e-06\n",
      " -6.91041350e-07 -2.30967999e-07 -1.09896064e-07  5.40167093e-08\n",
      "  2.42143869e-08  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "with open('results/mnist mean_importance.pkl', 'rb') as f:\n",
    "    mean_imp = pickle.load(f)\n",
    "print(mean_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "permutation = []\n",
    "for i in range(512):\n",
    "    filename = 'results/mnist permutation_test {}.pkl'.format(i)\n",
    "    with open(filename, 'rb') as f:\n",
    "        permutation.append(pickle.load(f)['scores'])\n",
    "permutation = np.array(permutation).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "with open('results/mnist feature_ablation.pkl', 'rb') as f:\n",
    "    ablation = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "with open('results/mnist univariate.pkl', 'rb') as f:\n",
    "    univariate = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioritized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 15, 25, 35, 45, 55, 65, 75, 85, 95]\n"
     ]
    }
   ],
   "source": [
    "num_features = list(range(5, 100, 10))\n",
    "device = torch.device('cuda', 0)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with PSAVE_GAU 5 (loss = 1.4456, acc = 0.4798)\n",
      "Done with PSAVE_GAU 15 (loss = 0.6887, acc = 0.7627)\n",
      "Done with PSAVE_GAU 25 (loss = 0.4072, acc = 0.8659)\n",
      "Done with PSAVE_GAU 35 (loss = 0.3274, acc = 0.8949)\n",
      "Done with PSAVE_GAU 45 (loss = 0.2723, acc = 0.9105)\n",
      "Done with PSAVE_GAU 55 (loss = 0.2673, acc = 0.9139)\n",
      "Done with PSAVE_GAU 65 (loss = 0.2406, acc = 0.9261)\n",
      "Done with PSAVE_GAU 75 (loss = 0.2184, acc = 0.9303)\n",
      "Done with PSAVE_GAU 85 (loss = 0.1811, acc = 0.9436)\n",
      "Done with PSAVE_GAU 95 (loss = 0.1724, acc = 0.9461)\n",
      "Done with PSAVE_POS 5 (loss = 1.7981, acc = 0.3504)\n",
      "Done with PSAVE_POS 15 (loss = 1.0013, acc = 0.6368)\n",
      "Done with PSAVE_POS 25 (loss = 0.5489, acc = 0.8120)\n",
      "Done with PSAVE_POS 35 (loss = 0.3954, acc = 0.8680)\n",
      "Done with PSAVE_POS 45 (loss = 0.3028, acc = 0.9044)\n",
      "Done with PSAVE_POS 55 (loss = 0.2796, acc = 0.9118)\n",
      "Done with PSAVE_POS 65 (loss = 0.2390, acc = 0.9244)\n",
      "Done with PSAVE_POS 75 (loss = 0.2184, acc = 0.9363)\n",
      "Done with PSAVE_POS 85 (loss = 0.2006, acc = 0.9395)\n",
      "Done with PSAVE_POS 95 (loss = 0.1907, acc = 0.9444)\n",
      "Done with PSAVE_BIO 5 (loss = 1.7987, acc = 0.3239)\n",
      "Done with PSAVE_BIO 15 (loss = 1.0914, acc = 0.6279)\n",
      "Done with PSAVE_BIO 25 (loss = 0.6337, acc = 0.7824)\n",
      "Done with PSAVE_BIO 35 (loss = 0.5917, acc = 0.7986)\n",
      "Done with PSAVE_BIO 45 (loss = 0.4883, acc = 0.8353)\n",
      "Done with PSAVE_BIO 55 (loss = 0.3526, acc = 0.8831)\n",
      "Done with PSAVE_BIO 65 (loss = 0.2866, acc = 0.9089)\n",
      "Done with PSAVE_BIO 75 (loss = 0.2654, acc = 0.9142)\n",
      "Done with PSAVE_BIO 85 (loss = 0.2088, acc = 0.9319)\n",
      "Done with PSAVE_BIO 95 (loss = 0.1928, acc = 0.9384)\n",
      "Done with PSAVE_EXP 5 (loss = 2.0100, acc = 0.2326)\n",
      "Done with PSAVE_EXP 15 (loss = 1.2747, acc = 0.5335)\n",
      "Done with PSAVE_EXP 25 (loss = 0.9314, acc = 0.6678)\n",
      "Done with PSAVE_EXP 35 (loss = 0.5849, acc = 0.7968)\n",
      "Done with PSAVE_EXP 45 (loss = 0.3923, acc = 0.8696)\n",
      "Done with PSAVE_EXP 55 (loss = 0.2504, acc = 0.9193)\n",
      "Done with PSAVE_EXP 65 (loss = 0.2430, acc = 0.9207)\n",
      "Done with PSAVE_EXP 75 (loss = 0.2323, acc = 0.9284)\n",
      "Done with PSAVE_EXP 85 (loss = 0.2021, acc = 0.9371)\n",
      "Done with PSAVE_EXP 95 (loss = 0.1721, acc = 0.9465)\n",
      "Done with PSAVE_N 5 (loss = 1.6488, acc = 0.3588)\n",
      "Done with PSAVE_N 15 (loss = 1.3678, acc = 0.4541)\n",
      "Done with PSAVE_N 25 (loss = 1.1291, acc = 0.5765)\n",
      "Done with PSAVE_N 35 (loss = 0.7721, acc = 0.7216)\n",
      "Done with PSAVE_N 45 (loss = 0.5987, acc = 0.7899)\n",
      "Done with PSAVE_N 55 (loss = 0.5311, acc = 0.8177)\n",
      "Done with PSAVE_N 65 (loss = 0.3708, acc = 0.8841)\n",
      "Done with PSAVE_N 75 (loss = 0.3016, acc = 0.9079)\n",
      "Done with PSAVE_N 85 (loss = 0.2753, acc = 0.9146)\n",
      "Done with PSAVE_N 95 (loss = 0.2318, acc = 0.9302)\n",
      "Done with GAU 5 (loss = 1.4059, acc = 0.4993)\n",
      "Done with GAU 15 (loss = 0.6067, acc = 0.7995)\n",
      "Done with GAU 25 (loss = 0.4087, acc = 0.8711)\n",
      "Done with GAU 35 (loss = 0.3117, acc = 0.9014)\n",
      "Done with GAU 45 (loss = 0.2609, acc = 0.9210)\n",
      "Done with GAU 55 (loss = 0.2063, acc = 0.9383)\n",
      "Done with GAU 65 (loss = 0.2001, acc = 0.9399)\n",
      "Done with GAU 75 (loss = 0.1922, acc = 0.9409)\n",
      "Done with GAU 85 (loss = 0.1761, acc = 0.9471)\n",
      "Done with GAU 95 (loss = 0.1578, acc = 0.9512)\n"
     ]
    }
   ],
   "source": [
    "importance = (psave_values_gau,psave_values_p,psave_values_b,psave_values_n,gau)\n",
    "names = ('PSAVE_GAU', 'PSAVE_POS', 'PSAVE_BIO', 'PSAVE_N','GAU')\n",
    "mnist_results = {name: {'values': imp} for (imp, name) in zip(importance, names)}\n",
    "\n",
    "for name in mnist_results.keys():\n",
    "    values = mnist_results[name]['values']\n",
    "    order = np.argsort(values)[::-1]\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for num in num_features:\n",
    "        # Subsample data\n",
    "        inds = order[:num]\n",
    "        inds = np.array([i in inds for i in range(784)])\n",
    "        train_small = train[:, inds]\n",
    "        val_small = val[:, inds]\n",
    "        test_small = test[:, inds]#(10000,5)\n",
    "        #Train model\n",
    "        model = train_model(train_small, Y_train, val_small, Y_val)\n",
    "        preds = model(test_small.to(device)).softmax(dim=1).cpu().data.numpy()/8\n",
    "        loss = log_loss(Y_test_np, preds)\n",
    "        acc = np.mean(np.argmax(preds, axis=1) == Y_test_np)\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "        print('Done with {} {} (loss = {:.4f}, acc = {:.4f})'.format(name, num, loss, acc))\n",
    "    \n",
    "    mnist_results[name]['accuracy'] = acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import MultipleLocator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 1, figsize=(20, 12))\n",
    "num_features = list(range(5, 100, 10))\n",
    "\n",
    "colors = ('tab:red', 'tab:gray', 'tab:green', 'tab:olive', 'tab:pink', 'tab:orange')\n",
    "\n",
    "# Selection\n",
    "ax = axarr\n",
    "plt.sca(ax)\n",
    "for name, color in zip(names, colors):\n",
    "    values = mnist_results[name]['accuracy']\n",
    "    plt.plot(num_features[4:-1], values[4:-1], color=color, label=name,\n",
    "             marker='o', linestyle='--',linewidth=4)\n",
    "\n",
    "plt.ylabel('Accuracy', fontsize=18)\n",
    "plt.xlabel('# Features', fontsize=18)\n",
    "\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.legend(loc='best',fontsize=30)\n",
    "plt.title('MNIST Important Features', fontsize=35)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = (psave_values, permutation, mean_imp, ablation, univariate,sage_values.values)\n",
    "names = ('PSAVE', 'Permutation Test', 'Mean Importance', 'Feature Ablation', 'Univariate','SAGE')\n",
    "mnist_results = {name: {'values': imp} for (imp, name) in zip(importance, names)}\n",
    "for name in mnist_results.keys():\n",
    "    values = mnist_results[name]['values']\n",
    "    order = np.argsort(values)[::-1]\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    for num in num_features:\n",
    "        # Subsample data\n",
    "        inds = order[:num]\n",
    "        inds = np.array([i in inds for i in range(784)])\n",
    "        train_small = train[:, inds]\n",
    "        val_small = val[:, inds]\n",
    "        test_small = test[:, inds]#(10000,5)\n",
    "        #Train model\n",
    "        model = train_model(train_small, Y_train, val_small, Y_val)\n",
    "        preds = model(test_small.to(device)).softmax(dim=1).cpu().data.numpy()/8\n",
    "        loss = log_loss(Y_test_np, preds)\n",
    "        acc = np.mean(np.argmax(preds, axis=1) == Y_test_np)\n",
    "        loss_list.append(loss)\n",
    "        acc_list.append(acc)\n",
    "        print('Done with {} {} (loss = {:.4f}, acc = {:.4f})'.format(name, num, loss, acc))\n",
    "    \n",
    "    mnist_results[name]['accuracy'] = acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 1, figsize=(20, 12))\n",
    "num_features = list(range(5, 100, 10))\n",
    "\n",
    "colors = ('tab:red', 'tab:gray', 'tab:green', 'tab:olive', 'tab:pink', 'tab:orange')\n",
    "\n",
    "# Selection\n",
    "ax = axarr\n",
    "plt.sca(ax)\n",
    "for name, color in zip(names, colors):\n",
    "    values = mnist_results[name]['accuracy']\n",
    "    plt.plot(num_features[4:-1], values[4:-1], color=color, label=name,\n",
    "             marker='o', linestyle='--',linewidth=4)\n",
    "\n",
    "plt.ylabel('Accuracy', fontsize=18)\n",
    "plt.xlabel('# Features', fontsize=18)\n",
    "\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.legend(loc='best',fontsize=30)\n",
    "plt.title('MNIST Important Features', fontsize=35)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
